"""
Snakemake pipeline for cross-species protein domain and phosphorylation site comparison
======================================================================================

This pipeline automates the following tasks:
1. Downloading proteomes for *Arabidopsis thaliana* and a comparison organism.
2. Padding with additional plant proteomes to improve OrthoFinder results.
3. Running OrthoFinder to identify orthologous proteins.
4. Extracting target ortholog groups for specific proteins of interest.
5. Running InterProScan to annotate protein domains.
6. Running MusiteDeep to predict phosphorylation sites.
7. Comparing domain and phosphorylation site predictions across orthologous pairs.
8. Summarizing the comparisons of domain and phosphorylation site predictions

Author: Cos van Eijck
"""

import os
import csv
import pandas as pd
import torch
from itertools import product, combinations
from collections import defaultdict
from subprocess import CalledProcessError, run
from fetch.proteins import get_structure_protein_combinations_cross_species
import tempfile


# -----------------------
# Configuration and Constants
# -----------------------

configfile: "config.yaml"
OUTPUT_DIR = "output"

ORGANISM1 = "arabidopsis_thaliana"
ORGANISM2_UPID = config["organism2_upid"]
ORG2_SAFE = ORGANISM2_UPID.lower()  # use UPID as safe filename prefix
TARGET_PROTEINS = config["target_proteins"]
TARGETS_FILE_STR = "_".join(sorted([g.strip().upper().replace("*", "STAR") for g in TARGET_PROTEINS]))
STRUCTURE_PROTEINS = config["structure_proteins"]
GEO_IDENTIFIER = config["geo_identifier"]

PADDING_UPIDS = [
    "UP000011115",  # Solanum tuberosum
    "UP000032141",  # Brassica oleracea
    "UP000321393",  # Cucumis melo
    "UP000077755",  # Daucus carota
    "UP000189703",  # Nelumbo nucifera
]

PADDING_PREFIXES = [
    "solanum_tuberosum",
    "brassica_oleracea",
    "cucumis_melo",
    "daucus_carota",
    "nelumbo_nucifera",
]

ANALYSIS_DIR = f"{OUTPUT_DIR}/{ORGANISM1}_vs_{ORG2_SAFE}"
os.makedirs(ANALYSIS_DIR, exist_ok=True)


# -----------------------
# Helper Functions
# -----------------------

def get_orthogroup_wildcards_from_checkpoint():
    """
    Retrieve orthogroups from the extract_targets checkpoint.

    Returns
    -------
    list of str
        A list of orthogroup identifiers used for downstream analyses.
    """
    ckpt = checkpoints.extract_targets.get(
        targets_file_str="_".join([g.replace("*", "STAR") for g in TARGET_PROTEINS])
    )
    ckpt_output = ckpt.output[0]
    df = pd.read_csv(ckpt_output, sep="\t", usecols=[0])
    orthogroups = [str(og) for og in df.iloc[:, 0]]
    return orthogroups


def parse_tsv(tsv_file, og):
    """
    Parse an Orthogroup TSV file and return all protein pairs for comparison.

    Parameters
    ----------
    tsv_file : str
        Path to the TSV file generated by the `extract_targets` step.
    og : str
        Orthogroup identifier to extract pairs for.

    Returns
    -------
    list of tuple
        List of (arabidopsis_protein, comparison_protein) pairs.
    """
    pairs_list = []
    with open(tsv_file) as f:
        next(f)
        for line in f:
            row_og, arab, organism2 = line.strip().split("\t")
            if row_og != og:
                continue
            arab_proteins = [p.split("|")[-1] for p in arab.split(";") if p.strip()]
            organism2_proteins = [p.split("|")[-1] for p in organism2.split(";") if p.strip()]
            pairs_list.extend(product(arab_proteins, organism2_proteins))
    return pairs_list

def get_expression_genes(targets_tsv, columns="3"):
    """
    Extract gene identifiers from a TSV file for one or more specified columns.

    Parameters
    ----------
    targets_tsv : str
        Path to the TSV file containing target orthogroup mappings.
    columns : str, optional
        Column(s) to extract, 1-based indexing.
        Supports:
        - single column: "3"
        - comma-separated: "2,4,7"
        - ranges: "3-5"
        Default: "3" (original behavior)

    Returns
    -------
    list of str
        Sorted unique gene identifiers found in the specified column(s).
    """

    # ---- Parse columns specification ----
    col_indices = set()

    for part in columns.split(","):
        part = part.strip()
        if "-" in part:
            start, end = part.split("-")
            col_indices.update(range(int(start) - 1, int(end)))
        else:
            col_indices.add(int(part) - 1)

    # ---- Extract genes ----
    genes = []

    with open(targets_tsv, "r", encoding="utf-8") as f:
        reader = csv.reader(f, delimiter="\t")
        next(reader, None)  # skip header

        for row in reader:
            for idx in col_indices:
                if idx >= len(row):
                    continue
                cell = row[idx].strip()
                if not cell:
                    continue

                # multiple entries in a single cell
                for entry in cell.split(";"):
                    entry = entry.strip()
                    if not entry:
                        continue

                    parts = entry.split("|")
                    if len(parts) > 1:
                        genes.append(parts[1])  # canonical ID
                    else:
                        genes.append(entry)

    return sorted(set(genes))


def get_genes_per_orthogroup(targets_tsv):
    """
    Extract genes per orthogroup from a TSV file.

    Parameters
    ----------
    targets_tsv : str
        Path to the TSV file containing orthogroup -> gene mappings.

    Returns
    -------
    dict
        Dictionary mapping orthogroup IDs to lists of gene identifiers.
        Example:
        {
            "OG0001150": ["Q9LJR3", "A0A1I9LSW4", ...],
            "OG0002379": ["P43254", "A0A1P8B2S1", ...]
        }
    """
    orthogroup_genes = {}

    with open(targets_tsv, "r", encoding="utf-8") as f:
        reader = csv.reader(f, delimiter="\t")
        header = next(reader)  # skip header

        for row in reader:
            orthogroup = row[0].strip()
            genes = []

            for cell in row[1:]:
                cell = cell.strip()
                if not cell:
                    continue

                for entry in cell.split(";"):
                    entry = entry.strip()
                    if not entry:
                        continue

                    parts = entry.split("|")
                    if len(parts) > 1:
                        genes.append(parts[2])
                    else:
                        genes.append(entry)

            orthogroup_genes[orthogroup] = sorted(set(genes))

    return orthogroup_genes


# -----------------------
# Rules
# -----------------------

rule all:
    """
    Ensure all structure-protein FASTA pairs, predictions, and visualizations are completed.
    Skip expression analysis if GEO_IDENTIFIER is empty.
    """
    input:
        # summaries
        f"{ANALYSIS_DIR}/summary/{TARGETS_FILE_STR}_interpro_summary.tsv",
        f"{ANALYSIS_DIR}/summary/{TARGETS_FILE_STR}_musitedeep_summary_SorT.tsv",
        f"{ANALYSIS_DIR}/summary/{TARGETS_FILE_STR}_musitedeep_summary_Y.tsv",
        f"{ANALYSIS_DIR}/intermediates/{TARGETS_FILE_STR}_targets.tsv",
        # tree directory
        expand(
            f"{ANALYSIS_DIR}/trees/{TARGETS_FILE_STR}/{{orthogroup}}.txt",
            orthogroup=lambda wildcards: get_orthogroup_wildcards_from_checkpoint()
        ),

        # expression (optional)
        *(
            [
                f"{ANALYSIS_DIR}/expression/{GEO_IDENTIFIER}/expression.tsv"
            ] if GEO_IDENTIFIER else []
        ),

        # Visualizations: phylogenetic trees
        expand(
            f"{ANALYSIS_DIR}/visualisation/{TARGETS_FILE_STR}/{{orthogroup}}_tree.svg",
            orthogroup=lambda wildcards: get_orthogroup_wildcards_from_checkpoint()
        ),

        # Visualizations: phosphorylation SorT
        expand(
            f"{ANALYSIS_DIR}/visualisation/{TARGETS_FILE_STR}/{{orthogroup}}_SorT.svg",
            orthogroup=lambda wildcards: get_orthogroup_wildcards_from_checkpoint()
        ),

        # Visualizations: phosphorylation Y
        expand(
            f"{ANALYSIS_DIR}/visualisation/{TARGETS_FILE_STR}/{{orthogroup}}_Y.svg",
            orthogroup=lambda wildcards: get_orthogroup_wildcards_from_checkpoint()
        )

# -----------------------
# 1. API Downloads
# -----------------------

rule download_proteome_arabidopsis:
    """
    Download the reference proteome for *Arabidopsis thaliana* from UniProt.
    """
    output:
        f"{ANALYSIS_DIR}/{ORGANISM1}_proteome.fasta"
    shell:
        """
        python3 -m fetch.proteomes \
            --upid 'UP000006548' \
            --prefix 'arabidopsis_thaliana' \
            --output_dir {ANALYSIS_DIR}
        """

rule download_proteome_comparison_organism:
    """
    Download the proteome for the comparison organism using UniProt proteome UPID.
    """
    output:
        fasta=f"{ANALYSIS_DIR}/{ORG2_SAFE}_proteome.fasta"
    shell:
        """
        python3 -m fetch.proteomes \
            --upid {ORGANISM2_UPID} \
            --prefix {ORG2_SAFE} \
            --output_dir {ANALYSIS_DIR}
        """


# Prepare padding proteomes for OrthoFinder
PADDING_ORGS = [
    (upid, prefix)
    for upid, prefix in zip(PADDING_UPIDS, PADDING_PREFIXES)
    if prefix != ORG2_SAFE
]

rule download_padding_proteomes:
    """
    Download additional plant proteomes to pad OrthoFinder analysis and improve orthology detection.
    """
    output:
        expand(f"{ANALYSIS_DIR}/{{prefix}}_proteome.fasta", prefix=[p[1] for p in PADDING_ORGS])
    params:
        upids=lambda wildcards: " ".join([p[0] for p in PADDING_ORGS]),
        prefixes=lambda wildcards: " ".join([p[1] for p in PADDING_ORGS])
    shell:
        """
        python3 -m fetch.proteomes \
            --upid {params.upids} \
            --prefix {params.prefixes} \
            --output_dir {ANALYSIS_DIR}
        """


# -----------------------
# 2. OrthoFinder
# -----------------------

rule run_orthofinder:
    """
    Run OrthoFinder to detect orthologous proteins between Arabidopsis and the comparison organism.
    """
    input:
        arab=f"{ANALYSIS_DIR}/{ORGANISM1}_proteome.fasta",
        comp=f"{ANALYSIS_DIR}/{ORG2_SAFE}_proteome.fasta",
        padding=expand(f"{ANALYSIS_DIR}/{{prefix}}_proteome.fasta", prefix=[p[1] for p in PADDING_ORGS])
    output:
        f"{ANALYSIS_DIR}/homology/Orthologues/Orthologues_arabidopsis_thaliana_proteome/arabidopsis_thaliana_proteome__v__{ORG2_SAFE}_proteome.tsv",
        f"{ANALYSIS_DIR}/homology/Resolved_Gene_Trees/Resolved_Gene_Trees.txt"
    shell:
        """
        /opt/conda/bin/conda run -n of3_env orthofinder -f {ANALYSIS_DIR}
        mkdir -p {ANALYSIS_DIR}/homology/
        cp -r {ANALYSIS_DIR}/OrthoFinder/Results*/* {ANALYSIS_DIR}/homology/
        rm -rf {ANALYSIS_DIR}/OrthoFinder/
        """


# -----------------------
# 3. Extract Target Proteins
# -----------------------

checkpoint extract_targets:
    """
    Extract orthologous groups containing the target proteins of interest.
    """
    input:
        f"{ANALYSIS_DIR}/homology/Orthologues/Orthologues_arabidopsis_thaliana_proteome/arabidopsis_thaliana_proteome__v__{ORG2_SAFE}_proteome.tsv"
    output:
        f"{ANALYSIS_DIR}/intermediates/{TARGETS_FILE_STR}_targets.tsv"
    params:
        targets_cmd_str=lambda wildcards: " ".join(TARGET_PROTEINS)
    shell:
        """
        mkdir -p {ANALYSIS_DIR}/intermediates/
        python -m extract.target_orthologs \
            {input} \
            -o {output} \
            -t {params.targets_cmd_str}
        """

rule extract_targets_trees:
    """
    Extract orthologous groups protein trees containing the target proteins of interest.
    """
    input:
        targets=f"{ANALYSIS_DIR}/intermediates/{TARGETS_FILE_STR}_targets.tsv",
        resolved_trees=f"{ANALYSIS_DIR}/homology/Resolved_Gene_Trees/Resolved_Gene_Trees.txt"
    output:
        f"{ANALYSIS_DIR}/trees/{TARGETS_FILE_STR}/{{orthogroup}}.txt",
    shell:
        """
        mkdir -p {ANALYSIS_DIR}/trees/{TARGETS_FILE_STR}
        python -m extract.orthogroup_trees \
            {input.targets} \
            -r {input.resolved_trees} \
            -o {ANALYSIS_DIR}/trees/{TARGETS_FILE_STR}
        """

# -----------------------
# 4. InterProScan
# -----------------------

rule interproscan_predict:
    """
    Run InterProScan to predict protein domains for each orthogroup.
    """
    input:
        f"{ANALYSIS_DIR}/homology/Orthogroup_Sequences/{{orthogroup}}.fa"
    output:
        tsv=f"{ANALYSIS_DIR}/domains/{TARGETS_FILE_STR}/{{orthogroup}}.tsv"
    threads: 2
    resources:
        mem_mb=2048
    params:
        tmp_dir=f"{ANALYSIS_DIR}/temp/interproscan_tmp"
    shell:
        """
        mkdir -p {ANALYSIS_DIR}/domains/{TARGETS_FILE_STR}/
        mkdir -p {params.tmp_dir}

        export TMPDIR={params.tmp_dir}
        export TEMP={params.tmp_dir}

        conda run -n bioenv interproscan.sh \
            -i {input} \
            -b "{ANALYSIS_DIR}/domains/{TARGETS_FILE_STR}/{wildcards.orthogroup}" \
            -cpu {threads} \
            -f tsv \
            --tempdir {params.tmp_dir} \
            --disable-precalc
        """

rule compare_interpro_pairs:
    """
    Compare InterPro domain predictions between orthologous protein pairs.
    """
    input:
        tsv=f"{ANALYSIS_DIR}/domains/{TARGETS_FILE_STR}/{{orthogroup}}.tsv",
        targets=f"{ANALYSIS_DIR}/intermediates/{TARGETS_FILE_STR}_targets.tsv"
    output:
        directory(f"{ANALYSIS_DIR}/domains/{TARGETS_FILE_STR}/{{orthogroup}}_comparison")
    run:
        outdir = output[0]
        os.makedirs(outdir, exist_ok=True)

        pairs_list = parse_tsv(input.targets, wildcards.orthogroup)
        if not pairs_list:
            print(f"No pairs found for {wildcards.orthogroup}, skipping.")
            return

        for protein1, protein2 in pairs_list:
            outfile = os.path.join(outdir, f"{protein1}__vs__{protein2}.tsv")
            shell(f"python -m compare.domains '{input.tsv}' '{protein1}' '{protein2}' -o '{outfile}'")

# -----------------------
# 5. MusiteDeep
# -----------------------

rule musitedeep_predict:
    """
    Run MusiteDeep to predict phosphorylation sites (S/T/Y residues) for each orthogroup.
    """
    input:
        f"{ANALYSIS_DIR}/homology/Orthogroup_Sequences/{{orthogroup}}.fa"
    output:
        f"{ANALYSIS_DIR}/phosphorylation/{TARGETS_FILE_STR}/{{orthogroup}}_general_phosphorylation_SorT.txt",
        f"{ANALYSIS_DIR}/phosphorylation/{TARGETS_FILE_STR}/{{orthogroup}}_general_phosphorylation_Y.txt"
    shell:
        """
        mkdir -p {ANALYSIS_DIR}/phosphorylation/{TARGETS_FILE_STR}/
        conda run -n musitedeep_env python predict.py \
            -input "{input}" \
            -output "{ANALYSIS_DIR}/phosphorylation/{TARGETS_FILE_STR}/{wildcards.orthogroup}" \
            -predict-type general \
            -residue-types S,T,Y
        """

rule compare_musitedeep_pairs:
    """
    Compare predicted phosphorylation sites between orthologous protein pairs using MSA mapping.
    """
    input:
        sort = f"{ANALYSIS_DIR}/phosphorylation/{TARGETS_FILE_STR}/{{orthogroup}}_general_phosphorylation_SorT.txt",
        y    = f"{ANALYSIS_DIR}/phosphorylation/{TARGETS_FILE_STR}/{{orthogroup}}_general_phosphorylation_Y.txt",
        msa  = f"{ANALYSIS_DIR}/homology/MultipleSequenceAlignments/{{orthogroup}}.fa",
        targets = f"{ANALYSIS_DIR}/intermediates/{TARGETS_FILE_STR}_targets.tsv"
    output:
        directory(f"{ANALYSIS_DIR}/phosphorylation/{TARGETS_FILE_STR}/{{orthogroup}}_comparison")
    run:
        outdir = output[0]
        os.makedirs(outdir, exist_ok=True)

        pairs_list = parse_tsv(input.targets, wildcards.orthogroup)
        if not pairs_list:
            print(f"No pairs found for {wildcards.orthogroup}, skipping.")
            return

        for protein1, protein2 in pairs_list:
            # output files per prediction type (SorT and Y)
            outfile1 = os.path.join(outdir, f"{protein1}__vs__{protein2}_SorT.tsv")
            outfile2 = os.path.join(outdir, f"{protein1}__vs__{protein2}_Y.tsv")

            # call the MSA-aware comparison for SorT
            cmd1 = (
                f"python -m compare.msa_ps_sites "
                f"'{input.sort}' '{input.msa}' '{protein1}' '{protein2}' "
                f"-o '{outfile1}'"
            )
            try:
                run(cmd1, check=True, shell=True)
            except CalledProcessError as e:
                print(f"Warning: compare for {protein1} vs {protein2} (SorT) failed: {e}")
                # continue to next pair

            # call the MSA-aware comparison for Y
            cmd2 = (
                f"python -m compare.msa_ps_sites "
                f"'{input.y}' '{input.msa}' '{protein1}' '{protein2}' "
                f"-o '{outfile2}'"
            )
            try:
                run(cmd2, check=True, shell=True)
            except CalledProcessError as e:
                print(f"Warning: compare for {protein1} vs {protein2} (Y) failed: {e}")
                # continue to next pair

# -----------------------
# 8. Summarization of Results
# -----------------------

rule summarize_interpro:
    """
    Summarize InterProScan domain comparison results.
    """
    input:
        dirs=expand(
            f"{ANALYSIS_DIR}/domains/{TARGETS_FILE_STR}/{{orthogroup}}_comparison",
            orthogroup=lambda wildcards: get_orthogroup_wildcards_from_checkpoint()
        )
    output:
        f"{ANALYSIS_DIR}/summary/{TARGETS_FILE_STR}_interpro_summary.tsv"
    run:
        dirs_str = ",".join(input.dirs)
        shell(f"python -m summarize.interproscan {dirs_str} {output}")

rule summarize_musitedeep:
    """
    Summarize MusiteDeep phosphorylation site comparisons.
    """
    input:
        dirs=expand(
            f"{ANALYSIS_DIR}/phosphorylation/{TARGETS_FILE_STR}/{{orthogroup}}_comparison",
            orthogroup=lambda wildcards: get_orthogroup_wildcards_from_checkpoint()
        )
    output:
        sort=f"{ANALYSIS_DIR}/summary/{TARGETS_FILE_STR}_musitedeep_summary_SorT.tsv",
        y=f"{ANALYSIS_DIR}/summary/{TARGETS_FILE_STR}_musitedeep_summary_Y.tsv"
    run:
        dirs_str = ",".join(input.dirs)
        shell(f"python -m summarize.musitedeep {dirs_str} {ANALYSIS_DIR}/summary/{TARGETS_FILE_STR}_musitedeep_summary.tsv")

# -----------------------
# 9. Boltz-2
# -----------------------

rule fetch_structure_sequences:
    """
    Fetch UniProt FASTA sequences for structure-protein pairs.
    """
    input:
        f"{ANALYSIS_DIR}/intermediates/{TARGETS_FILE_STR}_targets.tsv"
    output:
        f"{ANALYSIS_DIR}/interactions/{TARGETS_FILE_STR}/{{prot1}}__vs__{{prot2}}.fa"
    run:
        shell("python -m fetch.proteins {wildcards.prot1} {wildcards.prot2} -o {output}")

rule boltz_predict:
    """
    Run Boltz-2 predictions on structure-protein FASTA pairs.
    """
    input:
        lambda wildcards: [
            f"{ANALYSIS_DIR}/interactions/{TARGETS_FILE_STR}/{p1}__vs__{p2}.fa"
            for p1, p2 in get_structure_protein_combinations_cross_species(
                f"{ANALYSIS_DIR}/intermediates/{TARGETS_FILE_STR}_targets.tsv",
                STRUCTURE_PROTEINS
            )
        ]
    output:
        directory(f"{ANALYSIS_DIR}/interactions/{TARGETS_FILE_STR}/boltz_{TARGETS_FILE_STR}")
    run:
        accelerator = "gpu" if torch.cuda.is_available() else "cpu"
        print(f"Boltz-2 running on {accelerator.upper()}")
        shell(
            f"conda run -n boltz2_env boltz predict "
            f"{ANALYSIS_DIR}/interactions/{TARGETS_FILE_STR} "
            f"--use_msa_server --accelerator {accelerator} --num_workers 1"
        )

rule compare_structures:
    """
    Compare predicted structures using RCSB FATCAT API.
    """
    input:
        lambda wildcards: [
            f"{ANALYSIS_DIR}/interactions/{TARGETS_FILE_STR}/boltz_{TARGETS_FILE_STR}/{p1}.cif",
            f"{ANALYSIS_DIR}/interactions/{TARGETS_FILE_STR}/boltz_{TARGETS_FILE_STR}/{p2}.cif"
        ]
    output:
        json=f"{ANALYSIS_DIR}/interactions/{TARGETS_FILE_STR}/comparisons/{{prot1}}__vs__{{prot2}}_alignment.json"
    params:
        method="fatcat-flexible"
    run:
        file1 = input[0]
        file2 = input[1]
        out_json = output.json
        method = params.method

        shell(
            f"python -m compare.structures "
            f"{file1} {file2} "
            f"--method {method} "
            f"--out {out_json}"
        )

# -----------------------
# 10. Gene expression
# -----------------------

if GEO_IDENTIFIER:

    rule fetch_expression_data:
        """
        Fetch a 10X expression dataset from GEO using a given GEO identifier.
        """
        output:
            barcodes=os.path.join(ANALYSIS_DIR, "expression", GEO_IDENTIFIER, "barcodes.tsv.gz"),
            features=os.path.join(ANALYSIS_DIR, "expression", GEO_IDENTIFIER, "features.tsv.gz"),
            matrix=os.path.join(ANALYSIS_DIR, "expression", GEO_IDENTIFIER, "matrix.mtx.gz")
        run:
            base_outdir = os.path.join(ANALYSIS_DIR, "expression")
            os.makedirs(base_outdir, exist_ok=True)
            geo_outdir = os.path.join(base_outdir, GEO_IDENTIFIER)
            os.makedirs(geo_outdir, exist_ok=True)
            shell(f"python -m fetch.geo_dataset {GEO_IDENTIFIER} -o {base_outdir}")

    rule check_expression:
        input:
            barcodes=os.path.join(ANALYSIS_DIR, "expression", GEO_IDENTIFIER, "barcodes.tsv.gz"),
            features=os.path.join(ANALYSIS_DIR, "expression", GEO_IDENTIFIER, "features.tsv.gz"),
            matrix=os.path.join(ANALYSIS_DIR, "expression", GEO_IDENTIFIER, "matrix.mtx.gz"),
            targets=f"{ANALYSIS_DIR}/intermediates/{TARGETS_FILE_STR}_targets.tsv"
        output:
            expression=os.path.join(ANALYSIS_DIR, "expression", GEO_IDENTIFIER, "expression.tsv"),
            raw_counts=os.path.join(ANALYSIS_DIR, "expression", GEO_IDENTIFIER, "expression_raw_counts.tsv")
        run:
            genes = get_expression_genes(input.targets)
            genes_str = ",".join(genes)

            shell(
                "Rscript check_target_expression.r "
                "-i {ANALYSIS_DIR}/expression/{GEO_IDENTIFIER}/ "
                "-g {genes_str} "
                "-t {output.expression}"
            )

            # Touch only if Rscript failed to create the file
            if not os.path.exists(output.expression):
                shell(f"touch {output.expression}")

# -----------------------
# 10. Visualisation
# -----------------------

rule visualize_tree:
    """
    Visualize phylogenetic trees, corresponding multiple sequence alignments, and domains.
    Produces a placeholder SVG if no tree is available.
    """
    input:
        tsv=f"{ANALYSIS_DIR}/domains/{TARGETS_FILE_STR}/{{orthogroup}}.tsv",
        msa=f"{ANALYSIS_DIR}/homology/MultipleSequenceAlignments/{{orthogroup}}.fa",
        tree=f"{ANALYSIS_DIR}/trees/{TARGETS_FILE_STR}/{{orthogroup}}.txt"
    output:
        f"{ANALYSIS_DIR}/visualisation/{TARGETS_FILE_STR}/{{orthogroup}}_tree.svg"
    run:
        shell(
            "xvfb-run -a conda run -n ete3_env python -m visualize.tree "
            "{input.tree} "
            "-a {input.msa} "
            "--domains {input.tsv} "
            "--max-domains 5 "
            "-o {output}"
        )

rule visualize_phosphorilation_sites:
    """
    Visualize orthogroup sequences with the phosphorylation sites highlighted
    in a color gradient.
    """
    input:
        sort=f"{ANALYSIS_DIR}/phosphorylation/{TARGETS_FILE_STR}/{{orthogroup}}_general_phosphorylation_SorT.txt",
        y=f"{ANALYSIS_DIR}/phosphorylation/{TARGETS_FILE_STR}/{{orthogroup}}_general_phosphorylation_Y.txt",
        seq=f"{ANALYSIS_DIR}/homology/Orthogroup_Sequences/{{orthogroup}}.fa",
        targets=f"{ANALYSIS_DIR}/intermediates/{TARGETS_FILE_STR}_targets.tsv"
    output:
        sort=f"{ANALYSIS_DIR}/visualisation/{TARGETS_FILE_STR}/{{orthogroup}}_SorT.svg",
        y=f"{ANALYSIS_DIR}/visualisation/{TARGETS_FILE_STR}/{{orthogroup}}_Y.svg"
    run:
        orthogroup_genes = get_genes_per_orthogroup(input.targets)
        genes_str = ",".join(orthogroup_genes[wildcards.orthogroup])

        shell(
            "python -m visualize.ps_sites "
            "{input.seq} "
            "-t {input.sort} "
            "-s {genes_str} "
            "--label_font 24 "
            "-o {output.sort}"
        )

        shell(
            "python -m visualize.ps_sites "
            "{input.seq} "
            "-t {input.y} "
            "-s {genes_str} "
            "--label_font 24 "
            "-o {output.y}"
        )
